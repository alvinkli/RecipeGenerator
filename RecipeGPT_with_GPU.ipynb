{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJxh55Iqwtmh"
      },
      "source": [
        "# Overview\n",
        "In this notebook, we try to give an quick example of model training, model inference, and model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L0Z39L8RuNZ"
      },
      "source": [
        "All the related files can be downloaded at https://drive.google.com/drive/folders/1h82H1QEnBHCetSYT-yQr_usBEo7E6cIX?usp=sharing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUKshMt8Skre"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TezzPJqlR_zF"
      },
      "source": [
        "copy the github repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgEndnkSKwfm",
        "outputId": "b679d4da-fb4e-462d-c60e-868f6189889c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'exp'...\n",
            "warning: the following paths have collided (e.g. case-sensitive paths\n",
            "on a case-insensitive filesystem) and only one from the same\n",
            "colliding group is in the working tree:\n",
            "\n",
            "  'training/gpt-2/README.md'\n",
            "  'training/gpt-2/Readme.md'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LARC-CMU-SMU/RecipeGPT-exp.git exp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl1MyUGOSHJg"
      },
      "source": [
        "install related packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLYrx7FOOr87",
        "outputId": "351a3377-06be-4b21-8f57-169a3340d7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\drewj\\Downloads\\RecipeGenerator-1\\exp\n"
          ]
        }
      ],
      "source": [
        "cd exp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB4Bl-i6Ovci",
        "outputId": "b29c3653-f6e1-4d5f-a67c-9cc5d59f2c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/cpcloud/ipython-autotime (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/cpcloud/ipython-autotime to c:\\users\\drewj\\appdata\\local\\temp\\pip-req-build-u1cutym5\n",
            "  Resolved https://github.com/cpcloud/ipython-autotime to commit 5a0603b344f8e4b610d0cedae984a4b55cfa3340\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting spacy==2.1.8\n",
            "  Downloading spacy-2.1.8.tar.gz (30.7 MB)\n",
            "     ---------------------------------------- 30.7/30.7 MB 9.9 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: still running...\n",
            "  Installing build dependencies: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cpcloud/ipython-autotime 'C:\\Users\\drewj\\AppData\\Local\\Temp\\pip-req-build-u1cutym5'\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × pip subprocess to install build dependencies did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [178 lines of output]\n",
            "      WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "      Collecting setuptools\n",
            "        Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "           ---------------------------------------- 1.2/1.2 MB 8.7 MB/s eta 0:00:00\n",
            "      Collecting wheel<0.33.0,>0.32.0\n",
            "        Downloading wheel-0.32.3-py2.py3-none-any.whl (21 kB)\n",
            "      Collecting Cython\n",
            "        Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
            "           ------------------------------------- 986.3/986.3 kB 12.4 MB/s eta 0:00:00\n",
            "      Collecting cymem<2.1.0,>=2.0.2\n",
            "        Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
            "      Collecting preshed<2.1.0,>=2.0.1\n",
            "        Downloading preshed-2.0.1.tar.gz (113 kB)\n",
            "           -------------------------------------- 113.7/113.7 kB 6.5 MB/s eta 0:00:00\n",
            "        Preparing metadata (setup.py): started\n",
            "        Preparing metadata (setup.py): finished with status 'done'\n",
            "      Collecting murmurhash<1.1.0,>=0.28.0\n",
            "        Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
            "      Collecting thinc<7.1.0,>=7.0.8\n",
            "        Downloading thinc-7.0.8.tar.gz (1.9 MB)\n",
            "           ---------------------------------------- 1.9/1.9 MB 11.1 MB/s eta 0:00:00\n",
            "        Preparing metadata (setup.py): started\n",
            "        Preparing metadata (setup.py): finished with status 'done'\n",
            "      Collecting blis<0.3.0,>=0.2.1\n",
            "        Downloading blis-0.2.4.tar.gz (1.5 MB)\n",
            "           ---------------------------------------- 1.5/1.5 MB 13.3 MB/s eta 0:00:00\n",
            "        Preparing metadata (setup.py): started\n",
            "        Preparing metadata (setup.py): finished with status 'done'\n",
            "      Collecting wasabi<1.1.0,>=0.0.9\n",
            "        Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "      Collecting srsly<1.1.0,>=0.0.6\n",
            "        Downloading srsly-1.0.6-cp39-cp39-win_amd64.whl (198 kB)\n",
            "           ------------------------------------- 198.9/198.9 kB 12.6 MB/s eta 0:00:00\n",
            "      Collecting numpy>=1.7.0\n",
            "        Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
            "           --------------------------------------- 14.7/14.7 MB 13.9 MB/s eta 0:00:00\n",
            "      Collecting plac<1.0.0,>=0.9.6\n",
            "        Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "      Collecting tqdm<5.0.0,>=4.10.0\n",
            "        Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "      Collecting colorama\n",
            "        Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "      Building wheels for collected packages: preshed, thinc, blis\n",
            "        Building wheel for preshed (setup.py): started\n",
            "        Building wheel for preshed (setup.py): finished with status 'error'\n",
            "        error: subprocess-exited-with-error\n",
            "      \n",
            "        Ã— python setup.py bdist_wheel did not run successfully.\n",
            "        â”‚ exit code: 1\n",
            "        â•°â”€> [40 lines of output]\n",
            "            running bdist_wheel\n",
            "            running build\n",
            "            running build_py\n",
            "            creating build\n",
            "            creating build\\lib.win-amd64-3.9\n",
            "            creating build\\lib.win-amd64-3.9\\preshed\n",
            "            copying preshed\\about.py -> build\\lib.win-amd64-3.9\\preshed\n",
            "            copying preshed\\__init__.py -> build\\lib.win-amd64-3.9\\preshed\n",
            "            creating build\\lib.win-amd64-3.9\\preshed\\tests\n",
            "            copying preshed\\tests\\test_counter.py -> build\\lib.win-amd64-3.9\\preshed\\tests\n",
            "            copying preshed\\tests\\test_hashing.py -> build\\lib.win-amd64-3.9\\preshed\\tests\n",
            "            copying preshed\\tests\\test_pop.py -> build\\lib.win-amd64-3.9\\preshed\\tests\n",
            "            copying preshed\\tests\\__init__.py -> build\\lib.win-amd64-3.9\\preshed\\tests\n",
            "            copying preshed\\counter.pyx -> build\\lib.win-amd64-3.9\\preshed\n",
            "            copying preshed\\maps.pyx -> build\\lib.win-amd64-3.9\\preshed\n",
            "            copying preshed\\counter.pxd -> build\\lib.win-amd64-3.9\\preshed\n",
            "            copying preshed\\maps.pxd -> build\\lib.win-amd64-3.9\\preshed\n",
            "            copying preshed\\__init__.pxd -> build\\lib.win-amd64-3.9\\preshed\n",
            "            running build_ext\n",
            "            building 'preshed.maps' extension\n",
            "            creating build\\temp.win-amd64-3.9\n",
            "            creating build\\temp.win-amd64-3.9\\Release\n",
            "            creating build\\temp.win-amd64-3.9\\Release\\preshed\n",
            "            C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt /EHsc /Tppreshed/maps.cpp /Fobuild\\temp.win-amd64-3.9\\Release\\preshed/maps.obj /Ox /EHsc\n",
            "            maps.cpp\n",
            "            preshed/maps.cpp(5728): error C2039: 'tp_print': is not a member of '_typeobject'\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include\\cpython/object.h(193): note: see declaration of '_typeobject'\n",
            "            preshed/maps.cpp(5740): error C2039: 'tp_print': is not a member of '_typeobject'\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include\\cpython/object.h(193): note: see declaration of '_typeobject'\n",
            "            preshed/maps.cpp(5749): error C2039: 'tp_print': is not a member of '_typeobject'\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include\\cpython/object.h(193): note: see declaration of '_typeobject'\n",
            "            preshed/maps.cpp(5755): error C2039: 'tp_print': is not a member of '_typeobject'\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include\\cpython/object.h(193): note: see declaration of '_typeobject'\n",
            "            preshed/maps.cpp(5761): error C2039: 'tp_print': is not a member of '_typeobject'\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include\\cpython/object.h(193): note: see declaration of '_typeobject'\n",
            "            preshed/maps.cpp(5767): error C2039: 'tp_print': is not a member of '_typeobject'\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include\\cpython/object.h(193): note: see declaration of '_typeobject'\n",
            "            preshed/maps.cpp(6129): warning C4996: '_PyUnicode_get_wstr_length': deprecated in 3.3\n",
            "            preshed/maps.cpp(6145): warning C4996: '_PyUnicode_get_wstr_length': deprecated in 3.3\n",
            "            error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.33.31629\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "            [end of output]\n",
            "      \n",
            "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "        ERROR: Failed building wheel for preshed\n",
            "        Running setup.py clean for preshed\n",
            "        Building wheel for thinc (setup.py): started\n",
            "        Building wheel for thinc (setup.py): finished with status 'done'\n",
            "        Created wheel for thinc: filename=thinc-7.0.8-cp39-cp39-win_amd64.whl size=2020685 sha256=3ede987d51fddc9142e409cd377ae24581e97fde533d51edd9e5bf81abbe9836\n",
            "        Stored in directory: c:\\users\\drewj\\appdata\\local\\pip\\cache\\wheels\\29\\a8\\ee\\c5b65003ac7b8b1a2f574fef3a20fcb3ff79748c7b5f7960d4\n",
            "        Building wheel for blis (setup.py): started\n",
            "        Building wheel for blis (setup.py): finished with status 'error'\n",
            "        error: subprocess-exited-with-error\n",
            "      \n",
            "        Ã— python setup.py bdist_wheel did not run successfully.\n",
            "        â”‚ exit code: 1\n",
            "        â•°â”€> [31 lines of output]\n",
            "            BLIS_COMPILER? None\n",
            "            running bdist_wheel\n",
            "            running build\n",
            "            running build_py\n",
            "            creating build\n",
            "            creating build\\lib.win-amd64-3.9\n",
            "            creating build\\lib.win-amd64-3.9\\blis\n",
            "            copying blis\\about.py -> build\\lib.win-amd64-3.9\\blis\n",
            "            copying blis\\benchmark.py -> build\\lib.win-amd64-3.9\\blis\n",
            "            copying blis\\__init__.py -> build\\lib.win-amd64-3.9\\blis\n",
            "            creating build\\lib.win-amd64-3.9\\blis\\tests\n",
            "            copying blis\\tests\\common.py -> build\\lib.win-amd64-3.9\\blis\\tests\n",
            "            copying blis\\tests\\test_dotv.py -> build\\lib.win-amd64-3.9\\blis\\tests\n",
            "            copying blis\\tests\\test_gemm.py -> build\\lib.win-amd64-3.9\\blis\\tests\n",
            "            copying blis\\tests\\__init__.py -> build\\lib.win-amd64-3.9\\blis\\tests\n",
            "            copying blis\\cy.pyx -> build\\lib.win-amd64-3.9\\blis\n",
            "            copying blis\\py.pyx -> build\\lib.win-amd64-3.9\\blis\n",
            "            copying blis\\cy.pxd -> build\\lib.win-amd64-3.9\\blis\n",
            "            copying blis\\__init__.pxd -> build\\lib.win-amd64-3.9\\blis\n",
            "            running build_ext\n",
            "            Processing blis\\cy.pyx\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\drewj\\AppData\\Local\\Temp\\pip-install-k893do97\\blis_cc13b18aaf544a2687c8481267075a6c\\blis\\cy.pxd\n",
            "              tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "            Processing blis\\py.pyx\n",
            "            C:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\drewj\\AppData\\Local\\Temp\\pip-install-k893do97\\blis_cc13b18aaf544a2687c8481267075a6c\\blis\\py.pyx\n",
            "              tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "            msvc\n",
            "            py_compiler msvc\n",
            "            {'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'HOSTTYPE': 'x86_64', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'LANG': 'C.UTF-8', 'OLDPWD': '/home/matt/repos/flame-blis', 'VIRTUAL_ENV': '/home/matt/repos/cython-blis/env3.6', 'USER': 'matt', 'PWD': '/home/matt/repos/cython-blis', 'HOME': '/home/matt', 'NAME': 'LAPTOP-OMKOB3VM', 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop', 'SHELL': '/bin/bash', 'TERM': 'xterm-256color', 'SHLVL': '1', 'LOGNAME': 'matt', 'PATH': '/home/matt/repos/cython-blis/env3.6/bin:/tmp/google-cloud-sdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/mnt/c/Users/matt/Documents/cmder/vendor/conemu-maximus5/ConEmu/Scripts:/mnt/c/Users/matt/Documents/cmder/vendor/conemu-maximus5:/mnt/c/Users/matt/Documents/cmder/vendor/conemu-maximus5/ConEmu:/mnt/c/Python37/Scripts:/mnt/c/Python37:/mnt/c/Program Files (x86)/Intel/Intel(R) Management Engine Components/iCLS:/mnt/c/Program Files/Intel/Intel(R) Management Engine Components/iCLS:/mnt/c/Windows/System32:/mnt/c/Windows:/mnt/c/Windows/System32/wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Program Files (x86)/Intel/Intel(R) Management Engine Components/DAL:/mnt/c/Program Files/Intel/Intel(R) Management Engine Components/DAL:/mnt/c/Program Files (x86)/Intel/Intel(R) Management Engine Components/IPT:/mnt/c/Program Files/Intel/Intel(R) Management Engine Components/IPT:/mnt/c/Program Files/Intel/WiFi/bin:/mnt/c/Program Files/Common Files/Intel/WirelessCommon:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/ProgramData/chocolatey/bin:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files/LLVM/bin:/mnt/c/Windows/System32:/mnt/c/Windows:/mnt/c/Windows/System32/wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Windows/System32/OpenSSH:/mnt/c/Program Files/nodejs:/mnt/c/Users/matt/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/matt/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/matt/AppData/Roaming/npm:/snap/bin:/mnt/c/Program Files/Oracle/VirtualBox', 'PS1': '(env3.6) \\\\[\\\\e]0;\\\\u@\\\\h: \\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[00m\\\\]\\\\$ ', 'VAGRANT_HOME': '/home/matt/.vagrant.d/', 'LESSOPEN': '| /usr/bin/lesspipe %s', '_': '/home/matt/repos/cython-blis/env3.6/bin/python'}\n",
            "            clang -c C:\\Users\\drewj\\AppData\\Local\\Temp\\pip-install-k893do97\\blis_cc13b18aaf544a2687c8481267075a6c\\blis\\_src\\config\\bulldozer\\bli_cntx_init_bulldozer.c -o C:\\Users\\drewj\\AppData\\Local\\Temp\\tmpq3burfqe\\bli_cntx_init_bulldozer.o -O2 -funroll-all-loops -std=c99 -D_POSIX_C_SOURCE=200112L -DBLIS_VERSION_STRING=\"0.5.0-6\" -DBLIS_IS_BUILDING_LIBRARY -Iinclude\\windows-x86_64 -I.\\frame\\3\\ -I.\\frame\\ind\\ukernels\\ -I.\\frame\\1m\\ -I.\\frame\\1f\\ -I.\\frame\\1\\ -I.\\frame\\include -IC:\\Users\\drewj\\AppData\\Local\\Temp\\pip-install-k893do97\\blis_cc13b18aaf544a2687c8481267075a6c\\blis\\_src\\include\\windows-x86_64\n",
            "            error: [WinError 2] The system cannot find the file specified\n",
            "            [end of output]\n",
            "      \n",
            "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "        ERROR: Failed building wheel for blis\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i8zOb52PMFju",
        "outputId": "254c73cf-58c9-4c39-f7de-f8b1cbad9f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/exp/training/gpt-2\n"
          ]
        }
      ],
      "source": [
        "cd /content/exp/training/gpt-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG3wRvrgR6cL"
      },
      "source": [
        "Download original GPT-2 model from OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "kkke3-rRMIx7",
        "outputId": "0fa07fc7-8a6a-4970-bfa6-29c23635743f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        Running setup.py clean for blis\n",
            "      Successfully built thinc\n",
            "      Failed to build preshed blis\n",
            "      WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "      Installing collected packages: wasabi, plac, cymem, wheel, srsly, setuptools, preshed, numpy, murmurhash, Cython, colorama, tqdm, blis, thinc\n",
            "        Running setup.py install for preshed: started\n",
            "        Running setup.py install for preshed: finished with status 'error'\n",
            "        error: subprocess-exited-with-error\n",
            "      \n",
            "        Ã— Running setup.py install for preshed did not run successfully.\n",
            "        â”‚ exit code: 1\n",
            "        â•°â”€> [9 lines of output]\n",
            "            running install\n",
            "            running build\n",
            "            running build_py\n",
            "            running build_ext\n",
            "            building 'preshed.maps' extension\n",
            "            C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -IC:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Users\\drewj\\AppData\\Local\\Programs\\Python\\Python39\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.33.31629\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt /EHsc /Tppreshed/maps.cpp /Fobuild\\temp.win-amd64-3.9\\Release\\preshed/maps.obj /Ox /EHsc\n",
            "            maps.cpp\n",
            "            c1xx: fatal error C1083: Cannot open source file: 'preshed/maps.cpp': No such file or directory\n",
            "            error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.33.31629\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "            [end of output]\n",
            "      \n",
            "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "      error: legacy-install-failure\n",
            "      \n",
            "      Ã— Encountered error while trying to install package.\n",
            "      â•°â”€> preshed\n",
            "      \n",
            "      note: This is an issue with the package mentioned above, not pip.\n",
            "      hint: See above for output from the failure.\n",
            "      WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "      WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "      WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "      \n",
            "      [notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
            "      [notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× pip subprocess to install build dependencies did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\drewj\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "python: can't open file 'c:\\Users\\drewj\\Downloads\\RecipeGenerator-1\\exp\\download_model.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python download_model.py 117M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_ef8y_TANj3v",
        "outputId": "ba03d222-562f-46ad-9ce6-76c28cdef882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vD22Np6nQdmM",
        "outputId": "e39b6587-f673-4f8a-9701-3288ebbc298d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parameter format not correct - \"content\".\n"
          ]
        }
      ],
      "source": [
        "ls '/content/drive/My Drive/share_RecipeGPT/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl17ig25RowG"
      },
      "source": [
        "# Example of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "el5pOuSmP6_w",
        "outputId": "aa96b9ad-9762-4b65-de9f-253deb3e4520"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_436/4104571332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mto_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"path = '%s/'\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"path_to_model = path + 'models/'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'src/path.py'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_write\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from src.save import save\n",
        "to_write = \"path = '%s/'\"%(os.getcwd())+'\\n'+\"path_to_model = path + 'models/'\"\n",
        "save('src/path.py', to_write, overwrite = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw49s20clg6l"
      },
      "source": [
        "copy the training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDY4DvOxYH88"
      },
      "outputs": [],
      "source": [
        "cp -r '/content/drive/My Drive/share_RecipeGPT/recipe1M_1218' /content/exp/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFmvFS8ZSS82"
      },
      "source": [
        "Start the Model training; \n",
        "It will save checkpoints automatically in /content/exp/training/gpt-2/checkpoint/example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4rZvMVMbNneA",
        "outputId": "de190892-150a-4527-c860-70b213e94c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:95: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:98: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-19 02:20:36.409709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-03-19 02:20:36.412411: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f5cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-19 02:20:36.412449: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-19 02:20:36.435015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-19 02:20:36.561469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-19 02:20:36.562433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f5cf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-19 02:20:36.562473: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-03-19 02:20:36.562893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-19 02:20:36.563669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-19 02:20:36.570906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-19 02:20:36.806908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-03-19 02:20:36.930437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-03-19 02:20:36.953450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-03-19 02:20:37.237863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-03-19 02:20:37.298952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-03-19 02:20:37.812626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-19 02:20:37.812867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-19 02:20:37.813747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-19 02:20:37.814453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-03-19 02:20:37.818744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-03-19 02:20:37.820748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-19 02:20:37.820783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-03-19 02:20:37.820798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-03-19 02:20:37.822074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-19 02:20:37.822931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-19 02:20:37.823738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:99: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:112: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/sample.py:66: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/sample.py:71: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:124: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:128: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:154: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:156: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:159: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From train_ppl_pickle.py:163: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2020-03-19 02:20:51.913581: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2020-03-19 02:20:52.014292: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2020-03-19 02:20:52.949394: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2020-03-19 02:20:52.984749: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "2020-03-19 02:20:53.234653: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "Loading checkpoint models/117M/model.ckpt\n",
            "Loading dataset...\n",
            "896401\n",
            "417\n",
            "Training...\n",
            "Calculating validation loss...\n",
            "  0% 0/500 [00:00<?, ?it/s]2020-03-19 02:21:21.511458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            " 20% 98/500 [01:25<05:45,  1.16it/s]interrupted\n",
            "Saving checkpoint/example/model-1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python train_ppl_pickle.py --dataset '/content/exp/recipe1M_1218/chunk.train' --model_name '117M' --val_dataset '/content/exp/recipe1M_1218/chunk.val' --val_every 3000 --sample_every 3000 --max_length 512 --batch_size 8 --val_batch_size 8 --val_batch_count 500 --run_name example --learning_rate 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAAwdGT2mrnF"
      },
      "source": [
        "Please copy the checkpoint to '/content/exp/training/gpt-2/models/' to test the model you just trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8p85lSATsmK"
      },
      "source": [
        "# Example of Inference\n",
        "only 5 testing cases are used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVMG9lLEhWvw"
      },
      "source": [
        "download the deployed model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFPDN6-JWO8l"
      },
      "outputs": [],
      "source": [
        "cp -r '/content/drive/My Drive/share_RecipeGPT/models/deployed/' '/content/exp/training/gpt-2/models/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYTeTy-ph9gz"
      },
      "source": [
        "run the inference "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "2Q-d5hLUTt4s",
        "outputId": "92df24d6-6f2f-4dfd-956d-41a5fd7f851e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from src import conditional_gen_dir\n",
        "from src.save import save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "8XA5wXX1cr7Z",
        "outputId": "97125655-3a69-4f42-a8cc-7d91936195b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 462.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved gpt-2/models/deployed/checkpoint\n",
            "time spent in encoding 0:00:00.024756\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/conditional_gen_dir.py:90: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/conditional_gen_dir.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/conditional_gen_dir.py:93: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/sample.py:66: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/sample.py:71: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /content/exp/training/gpt-2/src/conditional_gen_dir.py:101: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/exp/training/gpt-2/models/deployed/model-606000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start decoding 2020-03-19 03:19:45.626037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:15<00:00,  7.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time spent in decoding 0:01:15.944274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "task_name='deployed'\n",
        "\n",
        "task_params = {'top_k': 3, 'model_name': task_name,\n",
        "          'filename': '/content/exp/data/recipe1M_example/test/X/',\n",
        "          'overwrite': True, 'tag': '_%s_k3_test'%(task_name)}\n",
        "\n",
        "to_write = {'to_write':'model_checkpoint_path: \"model-606000\"\\n'}\n",
        "modelpath = {'modelpath':'gpt-2/models/%s/checkpoint'%(task_name)}\n",
        "\n",
        "save(modelpath['modelpath'], to_write['to_write'], overwrite = True)\n",
        "\n",
        "conditional_gen_dir.interact_model(**task_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmUvYKfig9g2"
      },
      "source": [
        "find the generated texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "GXReCaesgxHU",
        "outputId": "c7b40c80-bd71-4cc9-cfbc-e4ead8235848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1264d.txt  1416d.txt  1559d.txt  570d.txt  761d.txt\n",
            "1264i.txt  1416i.txt  1559i.txt  570i.txt  761i.txt\n",
            "1264t.txt  1416t.txt  1559t.txt  570t.txt  761t.txt\n"
          ]
        }
      ],
      "source": [
        "ls '/content/exp/data/recipe1M_example/test/generation_deployed_k3_test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I93JzNFageu5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXAma6T4n5cp"
      },
      "source": [
        "# Performance evaluation\n",
        "only 5 testing cases are used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q6-rS5mJoAT9",
        "outputId": "171aa7ac-af6c-4268-aa4d-ee0efb322b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/exp/analysis\n"
          ]
        }
      ],
      "source": [
        "cd /content/exp/analysis/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "szIVgZROpjJr",
        "outputId": "569cf763-c452-4fc9-d5e5-f1228ab19b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "MOm1nD2-oSnx",
        "outputId": "d3b214bc-1119-4b6e-e023-a1d446af0126"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ]
        }
      ],
      "source": [
        "from dependency import parent_dir\n",
        "from common.basics import *\n",
        "from common.save import save_pickle, load_pickle, save\n",
        "import spacy\n",
        "from utils.evaluation import evaluation\n",
        "from utils.metrics import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMqZCzRSn9uo"
      },
      "outputs": [],
      "source": [
        "database = load_pickle('/content/drive/My Drive/share_RecipeGPT/big_data/database.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrg2_SSrpQKu"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from rouge import Rouge, FilesRouge\n",
        "from torchnlp._third_party.lazy_loader import LazyLoader\n",
        "from torchnlp.metrics import get_moses_multi_bleu\n",
        "\n",
        "def full_moses_multi_bleu(original, generation):\n",
        "    '''\n",
        "    This script wraps the multi-bleu.perl in python\n",
        "    It refers the get_moses_multi_bleu in torchnlp.metrics, \n",
        "    but it returns the scores in detail, not limit to the overall BLEU\n",
        "    \n",
        "    Args:\n",
        "        original: String to the txt file\n",
        "        generation: String to the txt file\n",
        "    Returns:\n",
        "        ans: A dict contains the BLEU scores in detail\n",
        "\n",
        "    '''\n",
        "    filereference = '../data/generation_ori.txt'\n",
        "    filehypothesis = '../data/generation_gen.txt'\n",
        "    save(filereference, original ,overwrite = True, print_ = False)\n",
        "    save(filehypothesis, generation ,overwrite = True, print_ = False)\n",
        "\n",
        "    bleu_cmd = ['perl', 'multi-bleu.perl', filehypothesis]\n",
        "    with open(filereference, \"r\") as read_pred:\n",
        "        bleu_out = subprocess.check_output(bleu_cmd, stdin=read_pred, stderr=subprocess.STDOUT)\n",
        "        bleu_out = bleu_out.decode(\"utf-8\")\n",
        "        \n",
        "        \n",
        "        BLEU = re.search(r\"BLEU = (.+?),\", bleu_out).group(1)\n",
        "        bleu_out = bleu_out.split(', ')\n",
        "        B1, B2, B3, B4, BP = bleu_out[-4].replace(' (BP=', '/').split('/')\n",
        "        ratio = bleu_out[-3].replace('ratio=', '')\n",
        "        hyp_len=bleu_out[-2].replace('hyp_len=', '')\n",
        "        ref_len=bleu_out[-1].replace('ref_len=', '').replace(')\\n', '')\n",
        "\n",
        "        ans = {'BLEU': BLEU, \n",
        "               'B1': B1, 'B2':B2, 'B3':B3, 'B4':B4, 'BP': BP, \n",
        "               'ratio':ratio, 'hyp_len': hyp_len, 'ref_len':ref_len}\n",
        "        ans = {i: float(v) for i, v in ans.items()}\n",
        "    return ans\n",
        "\n",
        "class ev(evaluation):\n",
        "    \"\"\" load the generation results and ground truth, then calculate the specified metrics \"\"\"\n",
        "    def __init__(self, filename, tag):\n",
        "        '''\n",
        "        Args:\n",
        "          filename: A directory to the files\n",
        "          tag: A name we assign to the directory, can be any string\n",
        "        \n",
        "        '''\n",
        "        self.dic = self.load_dic({}, filename, tag)\n",
        "        self.ori = tag\n",
        "        self.gens = []\n",
        "        self.sp = spacy.load('en_core_web_lg')\n",
        "        self.rouge = Rouge()\n",
        "        self.filesrouge = FilesRouge()\n",
        "\n",
        "    def ingr_f1(self, root = True):\n",
        "        value, number = [], []\n",
        "        for i, v in tqdm.tqdm(self.dic.items()):\n",
        "            true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
        "            if root:\n",
        "                true, pred = self.ingr(true), self.ingr(pred)\n",
        "            scores = metrics(true, pred)\n",
        "            value.append(scores.f1())\n",
        "            number.append(len(set(pred)))\n",
        "        avg = sum(value)/len(value)\n",
        "        return {'ingredient_f1':avg, 'average ingr number':sum(number)/len(number) } \n",
        "        \n",
        "    def jaccard(self, generate = 'ingr'):\n",
        "        assert generate in ['ingr','instr','human']\n",
        "        jaccard = []\n",
        "        for i, v in tqdm.tqdm(self.dic.items()):\n",
        "            if generate == 'ingr':\n",
        "                true, pred = v['%s_ingr'%(self.ori)], v['%s_ingr'%(self.gen)]\n",
        "                true, pred = self.ingr(true), self.ingr(pred)\n",
        "            elif generate == 'instr':\n",
        "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.gen)]\n",
        "                true, pred = self.ingr(true), self.instr(pred)\n",
        "            elif generate == 'human':   \n",
        "                true, pred = v['%s_ingr'%(self.ori)], v['%s_instr'%(self.ori)]\n",
        "                true, pred = self.ingr(true), self.instr(pred)\n",
        "            true, pred = set(true), set(pred)\n",
        "            \n",
        "            intersect = len(true & pred)\n",
        "            similarity = intersect /(len(true)+len(pred) - intersect)\n",
        "            jaccard.append(similarity)\n",
        "    \n",
        "        return {generate: sum(jaccard)/len(jaccard)}\n",
        "    \n",
        "    def instr(self, directions):\n",
        "        instr = self.sp(directions)\n",
        "        root_instr = []\n",
        "        for chunk in instr.noun_chunks:\n",
        "            idx_rootnoun = chunk.end - 1\n",
        "            str_rootnoun = instr[idx_rootnoun].lemma_\n",
        "            if str_rootnoun in database:\n",
        "                root_instr.append(str_rootnoun)\n",
        "        return root_instr\n",
        "    \n",
        "    def ingr(self, lst):\n",
        "        '''\n",
        "        Args: \n",
        "          lst: a list of ingredient names\n",
        "        Returns:\n",
        "          root_match: a list of root nouns\n",
        "        '''\n",
        "        hl = [[{'text':x, 'highlight': None} for x in i.split(' ')] for i in lst]\n",
        "        root_match = []\n",
        "        for i, ingr in enumerate(lst):\n",
        "            if ' ' not in ingr:\n",
        "                hl[i][0]['highlight'] = 'wrong'\n",
        "                doc = self.sp(ingr)\n",
        "                root_match.append(doc[0].lemma_)\n",
        "            else:\n",
        "                phrase = 'Mix the %s and water.'%ingr\n",
        "                doc = self.sp(phrase)\n",
        "                \n",
        "                last_chunk = None\n",
        "                for chunk in doc.noun_chunks:\n",
        "                    if chunk.text != 'water':\n",
        "                        last_chunk = chunk\n",
        "                if not last_chunk:\n",
        "                    root_match.append('CANNOT_DETECT')\n",
        "                else:\n",
        "                    found = False\n",
        "                    for j, word in enumerate(hl[i]):\n",
        "                        if doc[last_chunk.end - 1].text in word['text']:\n",
        "                            hl[i][j]['highlight'] = 'wrong' \n",
        "                            root_match.append(doc[last_chunk.end - 1].lemma_)\n",
        "                            found = True\n",
        "                            break\n",
        "                    if not found:\n",
        "                        root_match.append('CANNOT_DETECT')\n",
        "                        \n",
        "        assert len(root_match) == len(lst)\n",
        "        return root_match\n",
        "\n",
        "    def full_bleu(self):\n",
        "        '''\n",
        "        the new implementation: return a dict of metrics\n",
        "        '''\n",
        "        ori, gen = '',''\n",
        "        for i, v in self.dic.items():            \n",
        "            ori += self.add_space(v['%s_instr'%(self.ori)])+ '\\n'\n",
        "            gen += self.add_space(v['%s_instr'%(self.gen)])+ '\\n'\n",
        "        ans = full_moses_multi_bleu(gen, ori)\n",
        "        \n",
        "        filereference = '../data/generation_ori.txt'\n",
        "        filehypothesis = '../data/generation_gen.txt'\n",
        "        \n",
        "        scores = self.filesrouge.get_scores(filehypothesis, filereference, avg = True)\n",
        "        ans.update({'R-L': scores['rouge-l']['f']})\n",
        "        return ans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "iJRZGfrapUvE",
        "outputId": "4bcec27d-9791-4cde-fc2e-455248e0082c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load /content/exp/data/recipe1M_example/test/y/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load /content/exp/data/recipe1M_example/test/generation_deployed_k3_test\n",
            "deployed_generation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00,  7.24it/s]\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.27it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>BLEU</th>\n",
              "      <th>BP</th>\n",
              "      <th>NTED</th>\n",
              "      <th>R-L</th>\n",
              "      <th>average ingr number</th>\n",
              "      <th>hyp_len</th>\n",
              "      <th>ingredient_f1</th>\n",
              "      <th>ratio</th>\n",
              "      <th>ref_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>deployed_generation</th>\n",
              "      <td>61.0</td>\n",
              "      <td>19.3</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>5.44</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.549659</td>\n",
              "      <td>0.4339</td>\n",
              "      <td>7.8</td>\n",
              "      <td>487.0</td>\n",
              "      <td>0.736068</td>\n",
              "      <td>0.623</td>\n",
              "      <td>782.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       B1    B2   B3   B4  BLEU     BP      NTED     R-L  \\\n",
              "deployed_generation  61.0  19.3  5.7  1.5  5.44  0.546  0.549659  0.4339   \n",
              "\n",
              "                     average ingr number  hyp_len  ingredient_f1  ratio  \\\n",
              "deployed_generation                  7.8    487.0       0.736068  0.623   \n",
              "\n",
              "                     ref_len  \n",
              "deployed_generation    782.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data = ev('/content/exp/data/recipe1M_example/test/y/', 'ori')\n",
        "data.append_dic('/content/exp/data/recipe1M_example/test/generation_deployed_k3_test', 'deployed_generation')\n",
        "\n",
        "results = {}\n",
        "for tag in data.gens:\n",
        "    print(tag)\n",
        "    data.gen = tag\n",
        "    ans = data.full_bleu()\n",
        "    ans.update(data.ingr_f1(root=True))\n",
        "    ans.update(data.instr_tree(stem_only = False))\n",
        "    results[tag] = ans\n",
        "display(pd.DataFrame(results).T)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "ae9b42876be7716e48a57f9874312e4d7d4ba3c63552faac6e21c37780863ecd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
